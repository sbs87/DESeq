Title
========================================================

This is an R Markdown document. Markdown is a simple formatting syntax for authoring web pages (click the **Help** toolbar button for more details on using R Markdown).

When you click the **Knit HTML** button a web page will be generated that includes both content as well as the output of any embedded R code chunks within the document. You can embed an R code chunk like this:

```{r}
rm(list=ls())
source("http://bioconductor.org/biocLite.R")
biocLite("BiocUpgrade")
source("http://stevenbsmith.net/")
#biocLite("DESeq")
#biocLite("pasilla")
library("DESeq")
datafile =system.file( "extdata/pasilla_gene_counts.tsv", package="pasilla" )
datafile
pasillaCountTable = read.table( datafile, header=TRUE, row.names=1 )


pasillaDesign = data.frame(
  row.names = colnames( pasillaCountTable ),
  condition = c( "untreated", "untreated", "untreated",
                 "untreated", "treated", "treated", "treated" ),
  libType = c( "single-end", "single-end", "paired-end",
               "paired-end", "single-end", "paired-end", "paired-end" ) )

pairedSamples = pasillaDesign$libType == "paired-end"
countTable = pasillaCountTable[ , pairedSamples ]
condition = pasillaDesign$condition[ pairedSamples ]
head(countTable)

cds = newCountDataSet( countTable, condition )
cds = estimateSizeFactors( cds )
sizeFactors( cds )
head( counts( cds, normalized=TRUE ) )
head(counts(cds))
library("reshape")
library("ggplot2")
temp<-melt(counts(cds))
temp2<-melt(counts(cds, normalized=TRUE ))
head(temp)
temp[temp$X1=="FBgn0025692",]
ggplot(temp2)+ geom_bar(aes(x=value,fill=X2))+ facet_wrap(~ X2,ncol=1)


cds = estimateDispersions( cds )
str( fitInfo(cds) )
plotDispEsts( cds )
head(fitInfo(cds))
head(counts(cds))
res = nbinomTest( cds, "untreated", "treated" )

plotMA(res)

## Under the hood of nbinomTest and nbinomTestForMatrices...

condA="untreated"
condB="treated"
colA <- conditions(cds) == condA
colB <- conditions(cds) == condB

#The following obtains pooled dispersions. DIspersions can be pooled or (??) for each cndition (I guess depending on the dispersion estimation algorithim)
#In this case they are the same
rawScvA <- fData(cds)[, paste("disp", dispTable(cds)[condA], 
                              sep = "_")]
rawScvB <- fData(cds)[, paste("disp", dispTable(cds)[condB], 
                              sep = "_")]

#Raw counts by condition (k)
countsA=counts(cds)[, colA]
countsB=counts(cds)[, colB]

#Size factors by condition (s)
sizeFactorsA=sizeFactors(cds)[colA]
sizeFactorsB=sizeFactors(cds)[colB]

#Bookkeeping
dispsA=rawScvA
dispsB=rawScvB

#Total counts per gene/condition
kAs <- rowSums(cbind(countsA))
kBs <- rowSums(cbind(countsB))

#mean of gene counts/size factors (pooled mean, q0 i think)
mus <- rowMeans(cbind(t(t(countsA)/sizeFactorsA), t(t(countsB)/sizeFactorsB)))

#choose the max for each gene between q0*sum(s) + alpha*q^2*s^2 and q0*sum(s)++ (this is variance, and I assume this chooses the max between the NB and poission model)
fullVarsA <- pmax(mus * sum(sizeFactorsA) + dispsA * mus^2 *sum(sizeFactorsA^2), mus * sum(sizeFactorsA) * (1 + 1e-08))
fullVarsB <- pmax(mus * sum(sizeFactorsB) + dispsB * mus^2 *sum(sizeFactorsB^2), mus * sum(sizeFactorsB) * (1 + 1e-08))

#  (v-q0*sum(s))/(q0*sum(s))^2 .. this is alpha.. solved for by using NB variance, means, and s (vinette, pg 4)
sumDispsA <- (fullVarsA - mus * sum(sizeFactorsA))/(mus *sum(sizeFactorsA))^2
sumDispsB <- (fullVarsB - mus * sum(sizeFactorsB))/(mus *sum(sizeFactorsB))^2

#For each of the counts in A
sapply(seq(along = kAs), function(i) {
  if (kAs[i] == 0 & kBs[i] == 0) 
    return(NA)
  ks <- 0:(kAs[i] + kBs[i]) #seq from 0 to gene i's total counts 

  pa <- dnbinom(ks, mu = mus[i] * sum(sizeFactorsA), size = 1/sumDispsA[i]) # my addition
  pb <- dnbinom(kAs[i] + kBs[i] - ks, mu = mus[i] * sum(sizeFactorsB), size = 1/sumDispsB[i]) # my addition

  
  #return density for the the range of all possible counts in gene i given q0*sum(s), dispersion parameter (1/alpha), for both conditions. this is p(a..A,b..B)=p(a)*p(b)|all possibilitites
  ps <- dnbinom(ks, mu = mus[i] * sum(sizeFactorsA), size = 1/sumDispsA[i]) * 
    dnbinom(kAs[i] + kBs[i] - ks, mu = mus[i] * sum(sizeFactorsB), size = 1/sumDispsB[i])

plot(ks,ps/sum(ps), col="black")
points(ks,pa/sum(pa),col="red")
points(ks,pb/sum(pb),col="blue")

abline(v=kAs[i],col="red")
abline(v=kBs[i],col="blue")

#return the probably of observing a and b counts under a negative binomial distribution gievn q0*sum(s) and 1/alpha. this is p(a=A,b=B)=p(A)*p(B)
  pobs <- dnbinom(kAs[i], mu = mus[i] * sum(sizeFactorsA), size = 1/sumDispsA[i]) * 
    dnbinom(kBs[i], mu = mus[i] * sum(sizeFactorsB), size = 1/sumDispsB[i])
  
  #If for some reason the observed probably doesn't match the calculated probability wihin the range of probabilites, stop 
  stopifnot(pobs == ps[kAs[i] + 1])
  
  #Calls numer (numerator?) the range of probabilities less than extreme as the observed count
  if (kAs[i] * sum(sizeFactorsB) < kBs[i] * sum(sizeFactorsA)) numer <- ps[1:(kAs[i] + 1)] else numer <- ps[(kAs[i] + 1):length(ps)]
  #retuens the smaller value between the two sized sum(all probabilities al as extreme)/(all probabilities) and 1
  min(1, 2 * sum(numer)/sum(ps))
kBs[i] /kAs[i] 
})

nbinomTestForMatrices(counts(cds)[, colA], counts(cds)[,colB], sizeFactors(cds)[colA], sizeFactors(cds)[colB],rawScvA, rawScvB)

```

